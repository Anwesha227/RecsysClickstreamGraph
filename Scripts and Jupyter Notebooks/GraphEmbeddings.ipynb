{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1514f05f",
   "metadata": {},
   "source": [
    "## Generating Graph Embeddings\n",
    "\n",
    "We have already consctructed our graphs. However, now we need a representation of the nodes, if we are to make meaningful comparisons between the various products that form the nodes of our graphs. We need a way to be able to 'compare' them. So, we need some embeddings to represent our nodes. In general, embeddings help us capture some kind of social relations in our graphs.\n",
    "\n",
    "We could get these embeddings using the [DeepWalk](https://arxiv.org/pdf/1403.6652.pdf) and [Node2Vec](https://arxiv.org/pdf/1607.00653.pdf) algorithms.\n",
    "\n",
    "We first need to generate [Random Walks](https://cse.iitkgp.ac.in/~pawang/courses/SC15/rw1.pdf) for our nodes to get their embeddings. In simple terms, Given a graph and a starting node, if we select a neighbor of it at random, and move to this neighbor, then select a neighbor of this neighbor and move to it, and continue to do so (say 50 times), the random sequence of nodes selected this way is a random walk on the graph of length 50.\n",
    "\n",
    "We can generate such walks multiple times for each node instead of just one, since each walk could be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0351e77",
   "metadata": {},
   "source": [
    "### Generating Embeddings using Deepwalk\n",
    "\n",
    "We first generate random walks for each node (let's say each of length 50 and 10 walks per node) and after we have these random paths of nodes we will train a Word2Vec (skip-gram) model to obtain the node embeddings.\n",
    "\n",
    "We will use the library [pecanpy](https://github.com/krishnanlab/PecanPy) for this. It will allow us to use both Deepwalk and Node2Vec by tweaking certain parameters. PecanPy is an ultra fast and memory efficient implementation of node2vec. The original implementations suffer from issues such as :\n",
    "\n",
    "    - Not having parallelized implementation of walk generation which is an inherently parallelizable task.\n",
    "    - Memory issues arising from preprocessing and storing of 2nd order transition probabilities. \n",
    "    - Using networkx to store graph, which is quite inefficient for large scale computation. \n",
    "    \n",
    "This [blogpost](https://towardsdatascience.com/run-node2vec-faster-with-less-memory-using-pecanpy-1bdf31f136de) discusses these issues in a lot more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d98fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pecanpy import pecanpy\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ad283",
   "metadata": {},
   "source": [
    "We will first look at product views. For this we can take either of the graphs we generated in before. Let us consider the undirected weighted graph for views for this analysis.\n",
    "\n",
    "We could just as easily pick one of the other event types and the other graph types for our analysis. We just need to change the filenames accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea276435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id1</th>\n",
       "      <th>product_id2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3601512</td>\n",
       "      <td>3601269</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100059274</td>\n",
       "      <td>3601306</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5100855</td>\n",
       "      <td>4804056</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100041977</td>\n",
       "      <td>100041934</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100057579</td>\n",
       "      <td>100057560</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846587</th>\n",
       "      <td>12300752</td>\n",
       "      <td>4803895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846588</th>\n",
       "      <td>100017063</td>\n",
       "      <td>6501098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846589</th>\n",
       "      <td>8800741</td>\n",
       "      <td>1005195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846590</th>\n",
       "      <td>25200369</td>\n",
       "      <td>23900098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846591</th>\n",
       "      <td>100051139</td>\n",
       "      <td>100042051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6846592 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_id1  product_id2  count\n",
       "0            3601512      3601269     37\n",
       "1          100059274      3601306     12\n",
       "2            5100855      4804056    880\n",
       "3          100041977    100041934      2\n",
       "4          100057579    100057560     11\n",
       "...              ...          ...    ...\n",
       "6846587     12300752      4803895      1\n",
       "6846588    100017063      6501098      1\n",
       "6846589      8800741      1005195      1\n",
       "6846590     25200369     23900098      1\n",
       "6846591    100051139    100042051      1\n",
       "\n",
       "[6846592 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views_graph = pd.read_parquet('../Data/Graphs/undir_weight_graph_views.parquet')\n",
    "views_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4713a417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in the graph is 211861\n",
      "The number of edges in the graph is 6846592\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of nodes in the graph is\", len(set(views_graph['product_id1'].unique()).union(views_graph['product_id2'].unique())))\n",
    "print(\"The number of edges in the graph is\", len(views_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e2fc5",
   "metadata": {},
   "source": [
    "Pecanpy accepts input graphs that have the '.edg' format. So we would first need to store our graph in that format. We store these graphs in the 'PecanPy_Graphs' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff022648",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_graph.to_csv('../Data/PecanPy_Graphs/undir_weight_graph_views.edg', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183260d",
   "metadata": {},
   "source": [
    "#### Random Walk Generation\n",
    "\n",
    "Pecanpy implements node2vec originally and node2vec uses a combination of the algorithms DFS and BFS to extract the random walks. This combination of algorithms is controlled by two parameters 'p' (return parameter) and 'q' (in-out parameter). For Deepwalk those are simply set to 1 each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b34f584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Deepwalk we simply set p=1 and q=1 \n",
    "v_graph = pecanpy.SparseOTF(p=1, q=1, workers=-1, verbose=True, extend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0892b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c268ac03402b4c38bd02b036d7c0bd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                               | 0/2118610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We have set weighted to True and set directed to False because we are using an undirected weighted graph for views.\n",
    "v_graph.read_edg('../Data/PecanPy_Graphs/undir_weight_graph_views.edg', weighted=True, directed=False)\n",
    "\n",
    "# We generate 10 random walks per node and each walk is of length 50\n",
    "walks = v_graph.simulate_walks(num_walks=10, walk_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8bfa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100028635', '100008532', '28718344', '100028626', '100028648', '28716341', '28721605', '28718996', '28721605', '28721604', '100044499', '28722269', '28718867', '28717988', '28717986', '28720817', '28717986', '28719275', '28717946', '28719275', '28717980', '28719115', '28719132', '28718352', '28722207', '45600073', '45600114', '45600109', '12718062', '12719529', '12713110', '12710815', '12705468', '12716207', '12715137', '12702049', '12707874', '12719390', '12708290', '100023385', '12718994', '12714511', '12700236', '12704352', '12705983', '12702915', '12703402', '12703401', '100031717', '100048700', '12714716']\n"
     ]
    }
   ],
   "source": [
    "# We look at one of the walks generated for the nodes\n",
    "print(walks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fec52b",
   "metadata": {},
   "source": [
    "Next, we train a word2vec model on these walks to convert them to embeddings.\n",
    "\n",
    "The parameter choices can be explained below :\n",
    "\n",
    "    - hs = 1 : for using hierarchical softmax\n",
    "    - sg = 1 : for using skipgrams \n",
    "    - vector_size = 128 : this is the size of our embeddings\n",
    "    - window = 5 : window size; Maximum distance between the current and predicted word within a sentence.\n",
    "    - min_count = 1 : to ignore words with total frequency less than 1\n",
    "    \n",
    "We set the seed to get predictable results each time we run this notebook.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a966ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(walks,  \n",
    "                 hs=1,  \n",
    "                 sg = 1,  \n",
    "                 vector_size=128,  \n",
    "                 window=5,\n",
    "                 min_count=1,\n",
    "                 workers=-1,\n",
    "                 seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65688c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Data/Models/deepwalk_undir_weight_graph_views.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed27c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = set(views_graph['product_id1'].unique()).union(views_graph['product_id2'].unique())\n",
    "vg_embeddings = []\n",
    "for i in product_ids:\n",
    "    try:\n",
    "        vg_embeddings.append({'product_id': i, 'embedding_vector': model.wv[str(i)]})\n",
    "    except:\n",
    "        print(i, \"Not Exist\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f343721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_graph_embeddings = pd.DataFrame(vg_embeddings)\n",
    "views_graph_embeddings.to_parquet('../Data/Embeddings/deepwalk_undir_weight_graph_views_embedding.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed229197",
   "metadata": {},
   "source": [
    "We have successfully saved our embeddings and the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e739a",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "### Generating embeddings using Node2vec\n",
    "\n",
    "We discussed above what p and q are. If p is large the random walks will be large, so it does exploration and if p is small we remain within local neighborhood. Similarly if q is small, depth first exploration will be favored and if q is large we focus on a breadth first exploration. \n",
    "\n",
    "We shall keep p as 1, but reduce the value of q. This helps us to kind of do in depth within the regional clusters.It will help us to discover clusters/communities of characters that frequently interact with each other or co-occur, which in our case, are products viewed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "563b685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_graph_n2v = pecanpy.SparseOTF(p=1, q=0.5, workers=-1, verbose=True, extend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec3fa32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6a4509bf744188a72ce4694cb334a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                               | 0/2118170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "views_graph_n2v.read_edg('../Data/PecanPy_Graphs/undir_weight_graph_views.edg', weighted=True, directed=False)\n",
    "\n",
    "walks = views_graph_n2v.simulate_walks(num_walks=10, walk_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fdce7",
   "metadata": {},
   "source": [
    "We train the Word2Vec model once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa59ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n2v = Word2Vec(walks,  \n",
    "                 hs=1,  \n",
    "                 sg = 1,  \n",
    "                 vector_size=128,  \n",
    "                 window=5,\n",
    "                 min_count=1,\n",
    "                 workers=-1,\n",
    "                 seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e5288e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n2v.save('../Data/Models/node2vec_undir_weight_graph_views.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b9cc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = set(views_graph['product_id1'].unique()).union(views_graph['product_id2'].unique())\n",
    "vg_embeddings_n2v = []\n",
    "for i in product_ids:\n",
    "    try:\n",
    "        vg_embeddings_n2v.append({'product_id': i, 'embedding_vector': model_n2v.wv[str(i)]})\n",
    "    except:\n",
    "        print(i, \"Not Exist\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_graph_embeddings_n2v = pd.DataFrame(vg_embeddings_n2v)\n",
    "views_graph_embeddings_n2v.to_parquet('../Data/Embeddings/node2vec_undir_weight_graph_views_embedding.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b3f25",
   "metadata": {},
   "source": [
    "So now we have saved the models and embeddings for both node2vec and our deepwalk models. We have done this for Product Views with the Unweighted Directed Graph We could also do it using the other graph variants for the other events. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
